Generating one batch to determine activation dimension...
Activation dimension: 4096
Training SAE:   9%|████▌                                                | 1725280/20000000 [00:58<08:03, 37806.36it/s]Traceback (most recent call last):
Step 100, Loss: 1.2109
Step 200, Loss: 0.9922
Step 300, Loss: 1.0312
Step 400, Loss: 1.9375
Step 500, Loss: 1.1641
Step 600, Loss: 1.0625
Step 700, Loss: 5.1250
Step 800, Loss: 1.7109
  File "/root/shard_discovery/sae_on_grad/train.py", line 114, in <module>
    main()
  File "/root/shard_discovery/sae_on_grad/train.py", line 80, in main
    metrics = trainer.train_step(batch)
  File "/root/shard_discovery/sae_on_grad/trainer.py", line 75, in train_step
    loss.backward()
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
